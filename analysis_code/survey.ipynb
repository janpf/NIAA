{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import httpagentparser\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import redis\n",
    "import seaborn as sns\n",
    "from scipy.stats import binom_test, linregress, pearsonr, spearmanr\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.style.reload_library()\n",
    "plt.style.use(['science'])\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "from edit_image import parameter_range\n",
    "from IA import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_csv = Path(\"survey\") / \"survey.csv\" \n",
    "plot_dir = Path(\"analysis\")  / \"survey\" / \"users\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    submission_csv = Path(\"survey\") / \"survey_NIMA.csv\" \n",
    "    plot_dir = Path(\"analysis\")  / \"survey\" / \"NIMA\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(plot_dir / \"small_vs\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(submission_csv)\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[\"leftChanges\"] = sub_df.apply(lambda row: min(utils.parameter_range[row[\"parameter\"]][\"range\"], key=lambda x:abs(x-row[\"leftChanges\"])), axis=1)\n",
    "sub_df[\"rightChanges\"] = sub_df.apply(lambda row: min(utils.parameter_range[row[\"parameter\"]][\"range\"], key=lambda x:abs(x-row[\"rightChanges\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sub_df.hashval.count()} images compared in {sub_df.groupby('userid').userid.count().count()} sessions\")\n",
    "sub_df.groupby(\"chosen\").chosen.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"leftNIMA\" in sub_df.columns and \"rightNIMA\" in sub_df.columns:\n",
    "    sub_df[\"chosen\"] = sub_df.apply(lambda row: \"leftImage\" if row.leftNIMA > row.rightNIMA else \"rightImage\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[\"default\"] = sub_df.apply(lambda row: parameter_range[row.parameter][\"default\"], axis=1)\n",
    "sub_df[\"leftChanges\"] = sub_df.apply(lambda row: float(row.leftChanges), axis=1)\n",
    "sub_df[\"rightChanges\"] = sub_df.apply(lambda row: float(row.rightChanges), axis=1)\n",
    "sub_df[\"leftChanges\"] = sub_df.apply(lambda row: 0 if math.isclose(row.leftChanges, 0) else row.leftChanges, axis=1)\n",
    "sub_df[\"rightChanges\"] = sub_df.apply(lambda row: 0 if math.isclose(row.rightChanges, 0) else row.rightChanges, axis=1)\n",
    "sub_df[\"leftChanges\"] = sub_df.apply(lambda row: row.default if math.isclose(row.leftChanges, row.default) else row.leftChanges, axis=1)\n",
    "sub_df[\"rightChanges\"] = sub_df.apply(lambda row: row.default if math.isclose(row.rightChanges, row.default) else row.rightChanges, axis=1)\n",
    "sub_df[\"leftChanges\"] = sub_df.apply(lambda row: round(row.leftChanges, 2), axis=1)\n",
    "sub_df[\"rightChanges\"] = sub_df.apply(lambda row: round(row.rightChanges, 2), axis=1)\n",
    "sub_df[\"bothSame\"] = sub_df.apply(lambda row: math.isclose(row.leftChanges, row.rightChanges), axis=1)\n",
    "\n",
    "sub_df[\"lRelDistDefault\"] = sub_df.apply(lambda row: abs((row.default) - (row.leftChanges)), axis=1)\n",
    "sub_df[\"rRelDistDefault\"] = sub_df.apply(lambda row: abs((row.default) - (row.rightChanges)), axis=1)\n",
    "sub_df[\"lRelDistDefault\"] = sub_df.apply(lambda row: 0 if math.isclose(row.lRelDistDefault, 0) else row.lRelDistDefault, axis=1)\n",
    "sub_df[\"rRelDistDefault\"] = sub_df.apply(lambda row: 0 if math.isclose(row.rRelDistDefault, 0) else row.rRelDistDefault, axis=1)\n",
    "sub_df[\"lRelDistDefault\"] = sub_df.apply(lambda row: round(row.lRelDistDefault, 2), axis=1)\n",
    "sub_df[\"rRelDistDefault\"] = sub_df.apply(lambda row: round(row.rRelDistDefault, 2), axis=1)\n",
    "sub_df[\"smallChange\"] = sub_df.apply(lambda row: row.leftChanges if row.lRelDistDefault < row.rRelDistDefault else row.rightChanges, axis=1)\n",
    "sub_df[\"largeChange\"] = sub_df.apply(lambda row: row.rightChanges if row.lRelDistDefault < row.rRelDistDefault else row.leftChanges, axis=1)\n",
    "sub_df[\"smallRelDistDefault\"] = sub_df.apply(lambda row: min(row.lRelDistDefault, row.rRelDistDefault), axis=1)\n",
    "sub_df[\"largeRelDistDefault\"] = sub_df.apply(lambda row: max(row.lRelDistDefault, row.rRelDistDefault), axis=1)\n",
    "sub_df[\"smallLargeRelDistDefault\"] = sub_df.apply(lambda row: abs((row.smallRelDistDefault) - (row.largeRelDistDefault)), axis=1)\n",
    "sub_df[\"smallLargeRelDistDefault\"] = sub_df.apply(lambda row: 0 if math.isclose(row.smallLargeRelDistDefault, 0) else row.smallLargeRelDistDefault, axis=1)\n",
    "sub_df[\"smallLargeRelDistDefault\"] = sub_df.apply(lambda row: round(row.smallLargeRelDistDefault, 2), axis=1)\n",
    "sub_df[\"changeSign\"] = sub_df.apply(lambda row: 0 if math.isclose(row.largeChange - row.default, 0) else row.largeChange - row.default, axis=1)\n",
    "sub_df[\"changeSign\"] = sub_df.apply(lambda row: np.sign(row.changeSign), axis=1)\n",
    "\n",
    "sub_df[\"smallChangeIsOriginal\"] = sub_df.apply(lambda row: math.isclose(row.smallChange, row.default), axis=1)\n",
    "\n",
    "sub_df[\"smallerChosen\"] = sub_df.apply(lambda row: not row.bothSame and ((math.isclose(row.smallChange, row.leftChanges) and row.chosen == \"leftImage\") or math.isclose(row.smallChange, row.rightChanges) and row.chosen == \"rightImage\"), axis=1)\n",
    "sub_df[\"largerChosen\"] = sub_df.apply(lambda row: not row.bothSame and ((math.isclose(row.largeChange, row.leftChanges) and row.chosen == \"leftImage\") or math.isclose(row.largeChange, row.rightChanges) and row.chosen == \"rightImage\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"leftNIMA\" in sub_df.columns and \"rightNIMA\" in sub_df.columns:\n",
    "    sub_df[\"chosenNIMA\"] = sub_df.apply(lambda row: \"leftImage\" if row.leftNIMA > row.rightNIMA else \"rightImage\", axis=1)\n",
    "    sub_df[\"sameNIMA\"] = sub_df.apply(lambda row: row.chosen == row.chosenNIMA, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = sub_df[sub_df.chosen != \"error\"]\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nestedDict = lambda: collections.defaultdict(nestedDict)  # infinitely deep dict\n",
    "\n",
    "chosenAsSmaller = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
    "chosenAsLarger = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
    "\n",
    "for row in clean_df.itertuples():\n",
    "    if row.bothSame or row.chosen==\"unsure\":\n",
    "        continue\n",
    "    if row.smallerChosen:\n",
    "        if row.chosen == \"leftImage\":\n",
    "            chosenAsSmaller[row.parameter][row.leftChanges].append(1)\n",
    "            chosenAsLarger[row.parameter][row.rightChanges].append(0)\n",
    "        elif row.chosen == \"rightImage\":\n",
    "            chosenAsSmaller[row.parameter][row.rightChanges].append(1)\n",
    "            chosenAsLarger[row.parameter][row.leftChanges].append(0)\n",
    "    else:\n",
    "        if row.chosen == \"leftImage\":\n",
    "            chosenAsLarger[row.parameter][row.leftChanges].append(1)\n",
    "            chosenAsSmaller[row.parameter][row.rightChanges].append(0)\n",
    "        elif row.chosen == \"rightImage\":\n",
    "            chosenAsLarger[row.parameter][row.rightChanges].append(1)\n",
    "            chosenAsSmaller[row.parameter][row.leftChanges].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in parameter_range.keys():\n",
    "\n",
    "    for change in chosenAsSmaller[param].keys():\n",
    "        chosenAsSmaller[param][change] = np.mean(chosenAsSmaller[param][change])\n",
    "\n",
    "    for change in chosenAsLarger[param].keys():\n",
    "        chosenAsLarger[param][change] = np.mean(chosenAsLarger[param][change])\n",
    "\n",
    "    try:\n",
    "        x, y = zip(*sorted([(k,v) for k,v in chosenAsLarger[param].items() if k < parameter_range[param][\"default\"]]))\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "        plt.plot(x, y, \"-x\", color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        x, y = zip(*sorted([(k,v) for k,v in chosenAsLarger[param].items() if k > parameter_range[param][\"default\"]]))\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "        plt.plot(x, y, \"-x\", color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    x, y = zip(*sorted(chosenAsSmaller[param].items()))\n",
    "    x = list(x)\n",
    "    y = list(y)\n",
    "    plt.plot(x, y, \"-x\", color=plt.rcParams['axes.prop_cycle'].by_key()['color'][1])\n",
    "\n",
    "    plt.hlines(y=0.5, xmin=min(parameter_range[param][\"range\"]), xmax=max(parameter_range[param][\"range\"]), linestyle=\"--\", color=\"grey\")\n",
    "    plt.vlines(x=parameter_range[param][\"default\"],ymin=0, ymax=1, linestyle=\"--\", color=\"orange\")\n",
    "\n",
    "    plt.ylabel(\"clicked(\\%)\")\n",
    "    plt.xlabel(\"change\")\n",
    "\n",
    "    plt.xlim(left=min(parameter_range[param][\"range\"]), right=max(parameter_range[param][\"range\"]))\n",
    "    plt.ylim(bottom=0, top=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_dir /\"params\" / (param + \".pdf\"))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nestedDict = lambda: collections.defaultdict(nestedDict)  # infinitely deep dict\n",
    "\n",
    "chosenAtAll = collections.defaultdict(lambda: collections.defaultdict(lambda: []))\n",
    "\n",
    "for row in clean_df.itertuples():\n",
    "    if row.bothSame or row.chosen==\"unsure\":\n",
    "        continue\n",
    "\n",
    "    if not row.smallChangeIsOriginal:\n",
    "        continue\n",
    "\n",
    "    if row.chosen == \"leftImage\":\n",
    "        chosenAtAll[row.parameter][row.leftChanges].append(1)\n",
    "        chosenAtAll[row.parameter][row.rightChanges].append(0)\n",
    "    elif row.chosen == \"rightImage\":\n",
    "        chosenAtAll[row.parameter][row.rightChanges].append(1)\n",
    "        chosenAtAll[row.parameter][row.leftChanges].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in parameter_range.keys():\n",
    "    for change in chosenAtAll[param].keys():\n",
    "        chosenAtAll[param][change] = np.mean(chosenAtAll[param][change])\n",
    "\n",
    "    try:\n",
    "        x, y = zip(*sorted([(k,v) for k,v in chosenAtAll[param].items() if k <= parameter_range[param][\"default\"]]))\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "        #plt.plot(x, y, \"-x\", color=\"blue\")\n",
    "        sns.regplot(x, y, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], marker=\"x\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        x, y = zip(*sorted([(k,v) for k,v in chosenAtAll[param].items() if k >= parameter_range[param][\"default\"]]))\n",
    "        x = list(x)\n",
    "        y = list(y)\n",
    "        #plt.plot(x, y, \"-x\", color=\"blue\")\n",
    "        sns.regplot(x, y, color=plt.rcParams['axes.prop_cycle'].by_key()['color'][0], marker=\"x\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    plt.hlines(y=0.5, xmin=min(parameter_range[param][\"range\"]), xmax=max(parameter_range[param][\"range\"]), linestyle=\"--\", color=\"grey\")\n",
    "    plt.vlines(x=parameter_range[param][\"default\"],ymin=0, ymax=1, linestyle=\"--\", color=\"orange\")\n",
    "\n",
    "    plt.ylabel(\"clicked(\\%)\")\n",
    "    plt.xlabel(\"change\")\n",
    "\n",
    "    plt.xlim(left=min(parameter_range[param][\"range\"]), right=max(parameter_range[param][\"range\"]))\n",
    "    plt.ylim(bottom=0, top=1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_dir /\"orig_params\" / (param + \".pdf\"))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzeDict = nestedDict()\n",
    "for key in parameter_range.keys():\n",
    "    analyzeDict[key][\"overall\"] = len(clean_df[clean_df.parameter == key])\n",
    "    analyzeDict[key][\"unsure_eq\"] = len(clean_df[(clean_df.parameter == key) & (clean_df.bothSame == True) & (clean_df.chosen == \"unsure\")])\n",
    "    analyzeDict[key][\"not_unsure_eq\"] = len(clean_df[(clean_df.parameter == key) & (clean_df.bothSame == True) & (clean_df.chosen != \"unsure\")])\n",
    "    analyzeDict[key][\"unsure_not_eq\"] = len(clean_df[(clean_df.parameter == key) & (clean_df.bothSame == False) & (clean_df.chosen == \"unsure\")])\n",
    "\n",
    "    tmp = clean_df[(clean_df.parameter == key) & (clean_df.bothSame == False) & (clean_df.chosen != \"unsure\")]\n",
    "    analyzeDict[key][\"smallerChosen\"] = len(tmp[(tmp.smallerChosen == True)])\n",
    "    analyzeDict[key][\"smallerChosenOrigPresent\"] = len(tmp[(tmp.smallerChosen == True) & (tmp.smallChangeIsOriginal == True)])\n",
    "    analyzeDict[key][\"largerChosen\"] = len(tmp[(tmp.largerChosen == True)])\n",
    "    analyzeDict[key][\"largerChosenOrigPresent\"] = len(tmp[(tmp.largerChosen == True) & (tmp.smallChangeIsOriginal == True)])\n",
    "\n",
    "    d1 = tmp[\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredChanges\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.chosen == \"leftImage\")][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.chosen == \"rightImage\")][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"chosenChanges\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.smallChangeIsOriginal == True)][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.smallChangeIsOriginal == True)][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredChangesOrigPresent\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.smallChangeIsOriginal == True) & (tmp.chosen == \"leftImage\")][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.smallChangeIsOriginal == True) & (tmp.chosen == \"rightImage\")][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"chosenChangesOrigPresent\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "\n",
    "    d1 = tmp[tmp.changeSign > 0][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[tmp.changeSign > 0][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredChangesPos\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.changeSign > 0) & (tmp.chosen == \"leftImage\")][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.changeSign > 0) & (tmp.chosen == \"rightImage\")][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"chosenChangesPos\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.changeSign > 0) & (tmp.smallChangeIsOriginal == True)][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.changeSign > 0) & (tmp.smallChangeIsOriginal == True)][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredChangesOrigPresentPos\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.changeSign > 0) & (tmp.smallChangeIsOriginal == True) & (tmp.chosen == \"leftImage\")][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.changeSign > 0) & (tmp.smallChangeIsOriginal == True) & (tmp.chosen == \"rightImage\")][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"chosenChangesOrigPresentPos\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "\n",
    "    d1 = tmp[tmp.changeSign < 0][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[tmp.changeSign < 0][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredChangesNeg\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.changeSign < 0) & (tmp.chosen == \"leftImage\")][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.changeSign < 0) & (tmp.chosen == \"rightImage\")][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"chosenChangesNeg\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.changeSign < 0) & (tmp.smallChangeIsOriginal == True)][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.changeSign < 0) & (tmp.smallChangeIsOriginal == True)][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredChangesOrigPresentNeg\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "    d1 = tmp[(tmp.changeSign < 0) & (tmp.smallChangeIsOriginal == True) & (tmp.chosen == \"leftImage\")][\"leftChanges\"].value_counts().to_dict()\n",
    "    d2 = tmp[(tmp.changeSign < 0) & (tmp.smallChangeIsOriginal == True) & (tmp.chosen == \"rightImage\")][\"rightChanges\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"chosenChangesOrigPresentNeg\"] = {k: d1.get(k, 0) + d2.get(k, 0) for k in set(d1.keys()).union(set(d2.keys()))}\n",
    "\n",
    "    analyzeDict[key][\"occuredRelChangesPos\"] = tmp[tmp.changeSign > 0][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"smallerChosenRelChangesPos\"] = tmp[(tmp.changeSign > 0) & (tmp.smallerChosen == True)][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredRelChangesOrigPresentPos\"] = tmp[(tmp.changeSign > 0) & (tmp.smallChangeIsOriginal == True)][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"smallerChosenRelChangesOrigPresentPos\"] = tmp[(tmp.changeSign > 0) & (tmp.smallerChosen == True) & (tmp.smallChangeIsOriginal == True)][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "\n",
    "    analyzeDict[key][\"occuredRelChangesNeg\"] = tmp[tmp.changeSign < 0][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"smallerChosenRelChangesNeg\"] = tmp[(tmp.changeSign < 0) & (tmp.smallerChosen == True)][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"occuredRelChangesOrigPresentNeg\"] = tmp[(tmp.changeSign < 0) & (tmp.smallChangeIsOriginal == True)][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "    analyzeDict[key][\"smallerChosenRelChangesOrigPresentNeg\"] = tmp[(tmp.changeSign < 0) & (tmp.smallerChosen == True) & (tmp.smallChangeIsOriginal == True)][\"smallLargeRelDistDefault\"].value_counts().to_dict()\n",
    "\n",
    "    chosenVS = tmp.groupby([\"smallerChosen\", \"smallChange\", \"largeChange\"])[[\"smallerChosen\"]].size().to_frame(\"size\").reset_index()\n",
    "    allComparisons = tmp.groupby([\"smallChange\", \"largeChange\"])[[\"smallChange\"]].size().to_frame(\"size\").reset_index()\n",
    "    for _, row in chosenVS[chosenVS.smallerChosen == True].iterrows():\n",
    "        if len(allComparisons[(allComparisons.smallChange == row[\"smallChange\"]) & (allComparisons.largeChange == row[\"largeChange\"])]) > 1:\n",
    "            raise KeyError(\"what?\")\n",
    "        analyzeDict[key][\"asSmallerChosenVS\"][row[\"smallChange\"]][row[\"largeChange\"]] = row[\"size\"] / allComparisons[(allComparisons.smallChange == row[\"smallChange\"]) & (allComparisons.largeChange == row[\"largeChange\"])].iloc[0][\"size\"]\n",
    "\n",
    "    chosenVS = tmp.groupby([\"largerChosen\", \"smallChange\", \"largeChange\"])[[\"largerChosen\"]].size().to_frame(\"size\").reset_index()\n",
    "    allComparisons = tmp.groupby([\"smallChange\", \"largeChange\"])[[\"largeChange\"]].size().to_frame(\"size\").reset_index()\n",
    "    for _, row in chosenVS[chosenVS.largerChosen == True].iterrows():\n",
    "        if len(allComparisons[(allComparisons.smallChange == row[\"smallChange\"]) & (allComparisons.largeChange == row[\"largeChange\"])]) > 1:\n",
    "            raise KeyError(\"what?\")\n",
    "        analyzeDict[key][\"asLargerChosenVS\"][row[\"largeChange\"]][row[\"smallChange\"]] = row[\"size\"] / allComparisons[(allComparisons.smallChange == row[\"smallChange\"]) & (allComparisons.largeChange == row[\"largeChange\"])].iloc[0][\"size\"]\n",
    "\n",
    "    if \"leftNIMA\" in sub_df.columns and \"rightNIMA\" in sub_df.columns:\n",
    "        analyzeDict[key][\"sameNIMA\"] = tmp[\"sameNIMA\"].value_counts().to_dict()\n",
    "\n",
    "    for corr in [\n",
    "        (\"smallerChosenRelChangesPos\", \"occuredRelChangesPos\"),\n",
    "        (\"smallerChosenRelChangesOrigPresentPos\", \"occuredRelChangesOrigPresentPos\"),\n",
    "        (\"smallerChosenRelChangesNeg\", \"occuredRelChangesNeg\"),\n",
    "        (\"smallerChosenRelChangesOrigPresentNeg\", \"occuredRelChangesOrigPresentNeg\"),\n",
    "        (\"chosenChangesPos\", \"occuredChangesPos\"),\n",
    "        (\"chosenChangesOrigPresentPos\", \"occuredChangesOrigPresentPos\"),\n",
    "        (\"chosenChangesNeg\", \"occuredChangesNeg\"),\n",
    "        (\"chosenChangesOrigPresentNeg\", \"occuredChangesOrigPresentNeg\"),\n",
    "    ]:\n",
    "        if \"rel\" in corr[0].lower():\n",
    "            pass\n",
    "        elif not \"rel\" in corr[0].lower():\n",
    "            if \"pos\" in corr[0].lower():\n",
    "                for change in [val for val in parameter_range[key][\"range\"] if val >= parameter_range[key][\"default\"]]:\n",
    "                    if not change in analyzeDict[key][corr[0]]:\n",
    "                        analyzeDict[key][corr[0]][change] = 0\n",
    "                    if not change in analyzeDict[key][corr[1]]:\n",
    "                        raise KeyError(f\"that's weird: {key} {analyzeDict[key][corr[1]].keys()} {change}\")\n",
    "            elif \"neg\" in corr[0].lower():\n",
    "                if len(analyzeDict[key][corr[0]]) > 1:  # lcontrast and vibrance\n",
    "                    for change in [val for val in parameter_range[key][\"range\"] if val <= parameter_range[key][\"default\"]]:\n",
    "                        if not change in analyzeDict[key][corr[0]]:\n",
    "                            analyzeDict[key][corr[0]][change] = 0\n",
    "                        if not change in analyzeDict[key][corr[1]]:\n",
    "                            raise KeyError(f\"that's weird: {key} {analyzeDict[key][corr[1]].keys()} {change}\")\n",
    "            else:\n",
    "                raise NotImplementedError(\"you forgot what you thought wasn't necessary\")\n",
    "        else:\n",
    "            raise \"what?\"\n",
    "\n",
    "        for val in analyzeDict[key][corr[0]].keys():\n",
    "            analyzeDict[key][corr[0]][val] /= analyzeDict[key][corr[1]][val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = sorted(parameter_range.keys(), key=lambda key: binom_test(analyzeDict[key][\"smallerChosen\"], n=analyzeDict[key][\"smallerChosen\"] + analyzeDict[key][\"largerChosen\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(params):\n",
    "    print(f\"{key}:\\t{analyzeDict[key]['overall']} | {(analyzeDict[key]['overall'] / len(clean_df)) * 100}\")\n",
    "    print(\n",
    "        \"\\tbinomial test overall w/o unsure:\\tp: {:05.4f}\".format(binom_test(analyzeDict[key][\"smallerChosen\"], n=analyzeDict[key][\"smallerChosen\"] + analyzeDict[key][\"largerChosen\"])),\n",
    "        f\"(x={analyzeDict[key]['smallerChosen']} | n={analyzeDict[key]['smallerChosen'] + analyzeDict[key]['largerChosen']})\",\n",
    "    )\n",
    "    print(\n",
    "        \"\\tbinomial test w/ orig. img. w/o unsure:\\tp: {:05.4f}\".format(binom_test(analyzeDict[key][\"smallerChosenOrigPresent\"], n=analyzeDict[key][\"smallerChosenOrigPresent\"] + analyzeDict[key][\"largerChosenOrigPresent\"])),\n",
    "        f\"(x={analyzeDict[key]['smallerChosenOrigPresent']} | n={analyzeDict[key]['smallerChosenOrigPresent'] + analyzeDict[key]['largerChosenOrigPresent']})\",\n",
    "    )\n",
    "    if \"leftNIMA\" in sub_df.columns and \"rightNIMA\" in sub_df.columns:\n",
    "            print(\"\\tsurvey == NIMA: {:04.2f}%\".format(analyzeDict[key][\"sameNIMA\"][True] / (analyzeDict[key][\"sameNIMA\"][True] + analyzeDict[key][\"sameNIMA\"][False]) * 100))\n",
    "\n",
    "    print(f\"\\tsmaller edit:\\t\\t{'{:.1f}%'.format(analyzeDict[key]['smallerChosenOrigPresent'] / (analyzeDict[key]['smallerChosenOrigPresent'] + analyzeDict[key]['largerChosenOrigPresent']) * 100)}\\t| {analyzeDict[key]['smallerChosenOrigPresent']}\")\n",
    "    print(f\"\\tlarger edit:\\t\\t{'{:.1f}%'.format(analyzeDict[key]['largerChosenOrigPresent'] / (analyzeDict[key]['smallerChosenOrigPresent'] + analyzeDict[key]['largerChosenOrigPresent']) * 100)}\\t| {analyzeDict[key]['largerChosenOrigPresent']}\")\n",
    "    print(f\"\\tunsure and equal:\\t{'{:.1f}%'.format(analyzeDict[key]['unsure_eq'] / analyzeDict[key]['overall'] * 100)}\\t| {analyzeDict[key]['unsure_eq']}\")\n",
    "    print(f\"\\tunsure but not equal:\\t{'{:.1f}%'.format(analyzeDict[key]['unsure_not_eq'] / analyzeDict[key]['overall'] * 100)}\\t| {analyzeDict[key]['unsure_not_eq']}\")\n",
    "    print(f\"\\tnot unsure but equal:\\t{'{:.1f}%'.format(analyzeDict[key]['not_unsure_eq'] / analyzeDict[key]['overall'] * 100)}\\t| {analyzeDict[key]['not_unsure_eq']}\")\n",
    "\n",
    "    print(\"\\tcorr. for pos. changes | one image original | larger relative changes == more clicks for original image?:\")\n",
    "    print(\"\\t\\tpearson:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*pearsonr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesOrigPresentPos\"].items())))))\n",
    "    print(\"\\t\\tspearman:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*spearmanr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesOrigPresentPos\"].items())))))\n",
    "    print(\"\\t\\tlinregr:\\tslope: {:05.3f} intercept: {:05.3f} corr. coeff: {:05.3f} p: {:05.4f} stderr: {:05.3f}\".format(*linregress(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesOrigPresentPos\"].items())))))\n",
    "\n",
    "    if len(analyzeDict[key][\"smallerChosenRelChangesOrigPresentNeg\"]) != 0 and key != \"vibrance\":\n",
    "        print(\"\\tcorr. for neg. changes | one image original | larger relative changes == more clicks for original image?:\")\n",
    "        print(\"\\t\\tpearson:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*pearsonr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesOrigPresentNeg\"].items())))))\n",
    "        print(\"\\t\\tspearman:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*spearmanr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesOrigPresentNeg\"].items())))))\n",
    "        print(\"\\t\\tlinregr:\\tslope: {:05.3f} intercept: {:05.3f} corr. coeff: {:05.3f} p: {:05.4f} stderr: {:05.3f}\".format(*linregress(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesOrigPresentNeg\"].items())))))\n",
    "\n",
    "    print(\"\\tcorr. for pos. changes | all | larger relative changes == more clicks for (more) original image?:\")\n",
    "    print(\"\\t\\tpearson:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*pearsonr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesPos\"].items())))))\n",
    "    print(\"\\t\\tspearman:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*spearmanr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesPos\"].items())))))\n",
    "    print(\"\\t\\tlinregr:\\tslope: {:05.3f} intercept: {:05.3f} corr. coeff: {:05.3f} p: {:05.4f} stderr: {:05.3f}\".format(*linregress(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesPos\"].items())))))\n",
    "\n",
    "    if len(analyzeDict[key][\"smallerChosenRelChangesNeg\"]) != 0 and key != \"vibrance\":\n",
    "        print(\"\\tcorr. for neg. changes | all | larger relative changes == more clicks for (more) original image?:\")\n",
    "        print(\"\\t\\tpearson:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*pearsonr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesNeg\"].items())))))\n",
    "        print(\"\\t\\tspearman:\\tcorr. coeff: {:05.3f} p: {:05.4f}\".format(*spearmanr(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesNeg\"].items())))))\n",
    "        print(\"\\t\\tlinregr:\\tslope: {:05.3f} intercept: {:05.3f} corr. coeff: {:05.3f} p: {:05.4f} stderr: {:05.3f}\".format(*linregress(*list(zip(*analyzeDict[key][\"smallerChosenRelChangesNeg\"].items())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_chosen_c = collections.Counter(clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")][\"smallerChosen\"])\n",
    "print(\"smallerChosen:\", smaller_chosen_c.most_common())\n",
    "print(smaller_chosen_c[False]/smaller_chosen_c[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")][\"smallerChosen\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")][\"smallerChosen\"], [True]*len(clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")][\"smallerChosen\"], [True]*len(clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[(~clean_df[\"bothSame\"]) & (clean_df[\"chosen\"] != \"unsure\")][\"smallerChosen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = clean_df[\"RTT(s)\"]\n",
    "no_afk_durations = durations[durations < 60]\n",
    "unsure_duration = durations[(durations < 60) & (clean_df[\"chosen\"] == \"unsure\")]\n",
    "not_unsure_duration = durations[(durations < 60) & (clean_df[\"chosen\"] != \"unsure\")]\n",
    "\n",
    "print(f\"average time for decision: {'{:.1f}'.format(no_afk_durations.mean())} seconds\")\n",
    "\n",
    "sns.histplot(data=clean_df,x=\"RTT(s)\", bins=range(0, int(no_afk_durations.max()) + 1))\n",
    "plt.gca().axvline(x=no_afk_durations.mean(), linestyle=\"--\", color=\"k\", label=\"average\")\n",
    "\n",
    "plt.xlim(left=-1, right=int(no_afk_durations.max()) + 2)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "plt.xticks(ticks=[i*10 for i in range(7)])\n",
    "\n",
    "plt.xlabel(\"seconds\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(plot_dir / \"decision-duration.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useragents = []\n",
    "for _, row in clean_df.iterrows():\n",
    "    useragents.append(httpagentparser.detect(row[\"useragent\"]))\n",
    "\n",
    "browser_count = collections.Counter([val[\"browser\"][\"name\"] for val in useragents])\n",
    "os_count = collections.Counter([val[\"os\"][\"name\"] for val in useragents])\n",
    "dist_count = collections.Counter([val[\"dist\"][\"name\"] for val in useragents if \"dist\" in val])\n",
    "\n",
    "print(browser_count)\n",
    "print(os_count)\n",
    "print(dist_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usercount = clean_df[[\"userid\", \"hashval\"]].rename(columns={\"hashval\": \"count\"}).groupby(\"userid\").count()\n",
    "print(f\"average number of decisions: {'{:.1f}'.format(float(usercount.mean()))}\")\n",
    "print(usercount.nlargest(5, \"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=usercount, bins=range(0, int(usercount.max()) + 11, 10), label=\"\")\n",
    "# sns.distplot(usercount, bins=range(0, int(usercount.max()) + 1, 10), hist_kws={\"align\": \"left\"})\n",
    "plt.gca().axvline(x=float(usercount.mean()), linestyle=\"--\", color=\"k\", label=\"average\")\n",
    "# plt.yticks(range(0, 14))\n",
    "plt.xlim(left=-1, right=int(usercount.max()) + 11)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "plt.xlabel(\"comparisons per session\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "plt.xticks(ticks=[i*100 for i in range(7)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(plot_dir / \"session-duration.pdf\")\n",
    "usercount.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usercount.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
