{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IA.utils import mapping, parameter_range\n",
    "from scipy import stats\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"analysis/not_uploaded/IA/AVA/.scratch.ckpts.IA.pexels.scores-one.change_regress.epoch-9.pth.txt\")\n",
    "df[\"img\"] = df[\"img\"].apply(lambda row: int(Path(row).stem))\n",
    "df[\"score\"] = df[\"score\"].apply(lambda row: eval(row)[0])\n",
    "\n",
    "with open(\"analysis/not_uploaded/IA/AVA/style_image_lists/styles.txt\") as f:\n",
    "    styles_dict = [(int(line.split(\" \")[0]), line.split(\" \")[1].strip()) for line in f.readlines()]\n",
    "    styles_dict = dict(styles_dict)\n",
    "\n",
    "with open(\"analysis/not_uploaded/IA/AVA/style_image_lists/train.jpgl\") as f:\n",
    "    train_files = [int(line) for line in f.readlines()]\n",
    "\n",
    "with open(\"analysis/not_uploaded/IA/AVA/style_image_lists/train.lab\") as f:\n",
    "    train_label = [int(line) for line in f.readlines()]\n",
    "\n",
    "train_files = defaultdict(lambda: -1, zip(train_files, train_label))\n",
    "\n",
    "with open(\"analysis/not_uploaded/IA/AVA/style_image_lists/test.jpgl\") as f:\n",
    "    test_files = [int(line) for line in f.readlines()]\n",
    "\n",
    "with open(\"analysis/not_uploaded/IA/AVA/style_image_lists/test.multilab\") as f:\n",
    "    test_label = [line.strip().split(\" \") for line in f.readlines()]\n",
    "    test_label = [[int(lab) for lab in line] for line in test_label]\n",
    "\n",
    "test_files = defaultdict(lambda: [], zip(test_files, test_label))\n",
    "\n",
    "df = df[df[\"img\"].isin(train_files) | df[\"img\"].isin(test_files)]\n",
    "df[\"mode\"] = df[\"img\"].apply(lambda row: \"train\" if row in train_files else \"test\")\n",
    "\n",
    "df[\"train_label\"] = df[\"img\"].apply(lambda row: train_files[row])\n",
    "df[\"test_label\"] = df[\"img\"].apply(lambda row: test_files[row])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df.columns if c not in [\"index\", \"img\"]]\n",
    "reg_df = df.dropna()\n",
    "train = reg_df[reg_df[\"mode\"]==\"train\"].reset_index()[features]\n",
    "test = reg_df[reg_df[\"mode\"]==\"test\"].reset_index()[features]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = OneVsRestClassifier(svm.LinearSVC(class_weight='balanced'), n_jobs=-1).fit(train.drop(columns=[\"mode\", \"train_label\", \"test_label\"]), train[\"train_label\"])\n",
    "reg.score(train.drop(columns=[\"mode\", \"train_label\", \"test_label\"]), train[\"train_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for est in reg.estimators_:\n",
    "    preds.append(est.predict(test.drop(columns=[\"mode\", \"train_label\", \"test_label\", \"pred\", \"y_pred\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [[] for _ in range(len(preds[0]))]\n",
    "for est in preds:\n",
    "    for i, row in enumerate(est):\n",
    "        y_pred[i].append(row)\n",
    "test[\"y_pred\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = reg.predict(test.drop(columns=[\"mode\", \"train_label\", \"test_label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"test_label\", \"y_pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"found\"] = test.apply(lambda row: row.test_label[row.pred-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(list(test[\"found\"]))/len(list(test[\"found\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"pred\"] = clf.predict(test.drop(columns=[\"mode\", \"train_label\", \"test_label\", \"pred\", \"found\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(test.drop(columns=[\"mode\", \"train_label\", \"test_label\", \"pred\", \"found\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs2 = [[1 if score > 1/14 else 0 for score in i] for i in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"test_label\", \"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "for i in range(14):\n",
    "    precs.append(sklearn.metrics.precision_score(test[\"test_label\"].apply(lambda row: row[i]), test[\"y_pred\"].apply(lambda row: row[i])))\n",
    "    print(precs[-1])\n",
    "print(\"avg\",sum(precs) / len(precs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"found\"] = test.apply(lambda row: row.test_label[row.pred-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(list(test[\"found\"]))/len(list(test[\"found\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "73342ffb4f39afd09b383dcd177331173d9f4e4f229d5295da570a820709ffee"
    }
   },
   "name": "Python 3.8.5 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
